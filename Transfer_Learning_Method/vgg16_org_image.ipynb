{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./for_transfer_learning/model/transfer_learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18_left_1.jpg\n",
      "[[1.0843887]]\n",
      "18_right_1.jpg\n",
      "[[1.2929449]]\n",
      "10_right_1.jpg\n",
      "[[1.7972897]]\n",
      "30_right_1.jpg\n",
      "[[1.8826276]]\n",
      "11_left_1.jpg\n",
      "[[1.1074884]]\n",
      "30_left_1.jpg\n",
      "[[1.9716761]]\n",
      "11_right_1.jpg\n",
      "[[1.2535536]]\n",
      "10_left_1.jpg\n",
      "[[1.7777907]]\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "def divide_img():\n",
    "    ra_dataframe  = pd.read_csv('./rough_data.csv', header=None)\n",
    "    files         = glob.glob('./right/*')\n",
    "    files.extend(glob.glob('./left/*'))\n",
    "    process_dataframe = pd.DataFrame(columns=['path','value','class'])\n",
    "    print(files)\n",
    "    for file_path in files:\n",
    "        left,right = file_path.split(\"/\", 1)\n",
    "        dire,right = right.split(\"/\", 1)\n",
    "        num,right  = right.split(\"_\",1)\n",
    "\n",
    "        row        = 0\n",
    "        col        = 0\n",
    "        if dire == 'left':\n",
    "            col = 0\n",
    "        else:\n",
    "            col = 1\n",
    "        row = int(num) - 1\n",
    "        ra_value = ra_dataframe.iloc[row,col]\n",
    "        if float(ra_value) < 1.5:\n",
    "            os.makedirs('./rough1.0-1.5_nod', exist_ok=True)\n",
    "            #divide image to six images\n",
    "            image = cv2.imread(file_path)\n",
    "            \n",
    "            store_path = './rough1.0-1.5_nod/' + str(row+1) + '_' + dire + '_1' + '.jpg'\n",
    "            cv2.imwrite(store_path, image)\n",
    "\n",
    "        elif float(ra_value) >= 1.5 and float(ra_value) < 2.0:\n",
    "            os.makedirs('./rough1.5-2.0_nod/', exist_ok=True)\n",
    "            image = cv2.imread(file_path)\n",
    "            store_path = './rough1.5-2.0_nod/' + str(row+1) + '_' + dire + '_1' + '.jpg'\n",
    "            cv2.imwrite(store_path, image)\n",
    "\n",
    "        elif float(ra_value) >= 2.0:\n",
    "            os.makedirs('./rough2.0-2.5_nod/', exist_ok=True)\n",
    "            image = cv2.imread(file_path)\n",
    "            store_path = './rough2.0-2.5_nod/' + str(row+1) + '_' + dire + '_1' + '.jpg'\n",
    "            cv2.imwrite(store_path, image)\n",
    "        \n",
    "def load_img(path):\n",
    "    img = skimage.io.imread(path)\n",
    "    img = img / 255.0\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "    resized_img = skimage.transform.resize(crop_img, (224, 224))[None, :, :, :]   # shape [1, 224, 224, 3]\n",
    "    return resized_img\n",
    "\n",
    "def load_data():\n",
    "    imgs   = {'rough1.0-1.5_nod': [] , 'rough1.5-2.0_nod': [],'rough2.0-2.5_nod': []}\n",
    "    answer = {'rough1.0-1.5_nod': [] , 'rough1.5-2.0_nod': [], 'rough2.0-2.5_nod': []}\n",
    "    #format 6_right_1\n",
    "    for k in imgs.keys():\n",
    "        dir = './' + k + '/'\n",
    "        for file in os.listdir(dir):\n",
    "            if not file.lower().endswith('.jpg'):\n",
    "                continue\n",
    "            try:\n",
    "                resized_img = load_img(os.path.join(dir, file))\n",
    "            except OSError:\n",
    "                continue\n",
    "            imgs[k].append(resized_img)\n",
    "            if k == 'rough1.0-1.5_nod':\n",
    "                answer[k].append(0.0)\n",
    "            elif k == 'rough1.5-2.0_nod':\n",
    "                answer[k].append(1.0)\n",
    "            elif k == 'rough2.0-2.5_nod':\n",
    "                answer[k].append(2.0)\n",
    "    \n",
    "    return imgs['rough1.0-1.5_nod'], imgs['rough1.5-2.0_nod'], imgs['rough2.0-2.5_nod'],answer['rough1.0-1.5_nod'],answer['rough1.5-2.0_nod'],answer['rough2.0-2.5_nod']\n",
    "\n",
    "class Vgg16:\n",
    "    vgg_mean = [103.939, 116.779, 123.68]\n",
    "\n",
    "    def __init__(self, vgg16_npy_path=None, restore_from=None):\n",
    "        # pre-trained parameters\n",
    "        try:\n",
    "            self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "        except FileNotFoundError:\n",
    "            print('Please download VGG16 parameters from here https://mega.nz/#!YU1FWJrA!O1ywiCS2IiOlUCtCpI6HTJOMrneN-Qdv3ywQP5poecM\\nOr from my Baidu Cloud: https://pan.baidu.com/s/1Spps1Wy0bvrQHH2IMkRfpg')\n",
    "\n",
    "        self.tfx = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "        self.tfy = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "        # Convert RGB to BGR\n",
    "        red, green, blue = tf.split(axis=3, num_or_size_splits=3, value=self.tfx * 255.0)\n",
    "        bgr = tf.concat(axis=3, values=[\n",
    "            blue - self.vgg_mean[0],\n",
    "            green - self.vgg_mean[1],\n",
    "            red - self.vgg_mean[2],\n",
    "        ])\n",
    "\n",
    "        # pre-trained VGG layers are fixed in fine-tune\n",
    "        conv1_1 = self.conv_layer(bgr, \"conv1_1\")\n",
    "        conv1_2 = self.conv_layer(conv1_1, \"conv1_2\")\n",
    "        pool1 = self.max_pool(conv1_2, 'pool1')\n",
    "\n",
    "        conv2_1 = self.conv_layer(pool1, \"conv2_1\")\n",
    "        conv2_2 = self.conv_layer(conv2_1, \"conv2_2\")\n",
    "        pool2 = self.max_pool(conv2_2, 'pool2')\n",
    "\n",
    "        conv3_1 = self.conv_layer(pool2, \"conv3_1\")\n",
    "        conv3_2 = self.conv_layer(conv3_1, \"conv3_2\")\n",
    "        conv3_3 = self.conv_layer(conv3_2, \"conv3_3\")\n",
    "        pool3   = self.max_pool(conv3_3, 'pool3')\n",
    "\n",
    "        conv4_1 = self.conv_layer(pool3, \"conv4_1\")\n",
    "        conv4_2 = self.conv_layer(conv4_1, \"conv4_2\")\n",
    "        conv4_3 = self.conv_layer(conv4_2, \"conv4_3\")\n",
    "        pool4   = self.max_pool(conv4_3, 'pool4')\n",
    "\n",
    "        conv5_1 = self.conv_layer(pool4, \"conv5_1\")\n",
    "        conv5_2 = self.conv_layer(conv5_1, \"conv5_2\")\n",
    "        conv5_3 = self.conv_layer(conv5_2, \"conv5_3\")\n",
    "        pool5 = self.max_pool(conv5_3, 'pool5')\n",
    "\n",
    "        # detach original VGG fc layers and\n",
    "        # reconstruct your own fc layers serve for your own purpose\n",
    "        self.flatten = tf.reshape(pool5, [-1, 7*7*512])\n",
    "        \n",
    "        self.fc6 = tf.layers.dense(self.flatten, 256, tf.nn.relu, name='fc6')\n",
    "        self.out = tf.layers.dense(self.fc6, 1, name='out')\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        if restore_from:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(self.sess, restore_from)\n",
    "        else:   # training graph\n",
    "            self.loss = tf.losses.mean_squared_error(labels=self.tfy, predictions=self.out)\n",
    "            self.train_op = tf.train.RMSPropOptimizer(0.001).minimize(self.loss)\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def max_pool(self, bottom, name):\n",
    "        return tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "    def conv_layer(self, bottom, name):\n",
    "        with tf.variable_scope(name):   # CNN's filter is constant, NOT Variable that can be trained\n",
    "            conv = tf.nn.conv2d(bottom, self.data_dict[name][0], [1, 1, 1, 1], padding='SAME')\n",
    "            lout = tf.nn.relu(tf.nn.bias_add(conv, self.data_dict[name][1]))\n",
    "            return lout\n",
    "\n",
    "    def train(self, x, y):\n",
    "        loss, _ = self.sess.run([self.loss, self.train_op], {self.tfx: x, self.tfy: y})\n",
    "        return loss\n",
    "\n",
    "    def predict(self, paths):\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        imgs   = {'test_nod': [] }\n",
    "        for k in imgs.keys():\n",
    "            dir = './' + k + '/'\n",
    "            for file in os.listdir(dir):\n",
    "                if not file.lower().endswith('.jpg'):\n",
    "                    continue\n",
    "                resized_img = load_img(os.path.join(dir, file))\n",
    "                length = self.sess.run(self.out, {self.tfx: resized_img})\n",
    "                print(file)\n",
    "                print(length)\n",
    "        \n",
    "    def save(self, path='./for_transfer_learning/model/transfer_learn'):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.sess, path, write_meta_graph=False)\n",
    "\n",
    "def train():\n",
    "    rough0_x, rough1_x, rough2_x , rough0_y, rough1_y, rough2_y = load_data()\n",
    "    # plot fake length distribution\n",
    "    rough0_y = np.resize(np.array(rough0_y),(len(rough0_y),1))\n",
    "    rough1_y = np.resize(np.array(rough1_y),(len(rough1_y),1))\n",
    "    rough2_y = np.resize(np.array(rough2_y),(len(rough2_y),1))\n",
    "    plt.hist(rough0_y, bins=20, label='rough0')\n",
    "    plt.hist(rough1_y, bins=10, label='rough1')\n",
    "    plt.hist(rough2_y, bins=10, label='rough2')\n",
    "    plt.legend()\n",
    "    plt.xlabel('length')\n",
    "    plt.show()\n",
    "    \n",
    "    xs = np.concatenate(rough0_x+rough1_x+rough2_x,axis=0)\n",
    "    ys = np.concatenate((rough0_y,rough1_y,rough2_y), axis=0)\n",
    "    vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy')\n",
    "    print('Net built')\n",
    "    for i in range(1000):\n",
    "        b_idx = np.random.randint(0, len(xs), 50)\n",
    "        train_loss = vgg.train(xs[b_idx], ys[b_idx])\n",
    "        print(i, 'train loss: ', train_loss)\n",
    "\n",
    "    vgg.save('./for_transfer_learning/model/transfer_learn')\n",
    "    \n",
    "def eval():\n",
    "    vgg = Vgg16(vgg16_npy_path='./for_transfer_learning/vgg16.npy',\n",
    "                restore_from='./for_transfer_learning/model/transfer_learn')\n",
    "    vgg.predict(\n",
    "        ['./rough1.0-1.5_node/6_right_6.jpg', './rough1.5-2.0/3_right_5.jpg','./rough1.0-1.5/14_right_6.jpg','./rough2.0-2.5/18_right_1.jpg'])\n",
    "if __name__ == '__main__':\n",
    "    #divide_img()\n",
    "    #train()\n",
    "    eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
